{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36c81141-57db-46d7-bae9-c407a50ab0b4",
   "metadata": {},
   "source": [
    "## Tarefa 3 — Hiperparâmetros do Random Forest (RF)\n",
    "\n",
    "### 1) Quais são os hiperparâmetros do RF?\n",
    "\n",
    "Os hiperparâmetros mais usados (os que de fato controlam desempenho, estabilidade e complexidade do modelo) são:\n",
    "\n",
    "n_estimators  \n",
    "max_features  \n",
    "bootstrap (e, quando aplicável, max_samples)  \n",
    "criterion  \n",
    "max_depth  \n",
    "min_samples_split  \n",
    "min_samples_leaf  \n",
    "max_leaf_nodes  \n",
    "min_impurity_decrease  \n",
    "ccp_alpha  \n",
    "class_weight (em classificação)  \n",
    "oob_score  \n",
    "random_state  \n",
    "n_jobs  \n",
    "warm_start  \n",
    "\n",
    "Observação prática: existem outros parâmetros na biblioteca (ex.: min_weight_fraction_leaf, verbose), mas os acima são os mais comuns e mais cobrados.\n",
    "\n",
    "### 2) Para que serve cada um deles?\n",
    "\n",
    "**n_estimators:** quantidade de árvores na floresta. Em geral, mais árvores aumentam a estabilidade e podem melhorar o desempenho (até certo ponto), mas aumentam tempo de treino e uso de memória.  \n",
    "\n",
    "**max_features:** número (ou proporção) de variáveis consideradas em cada split da árvore. É um dos principais responsáveis por “descorrelacionar” as árvores; valores menores aumentam diversidade e costumam reduzir overfitting, mas podem reduzir desempenho se ficar baixo demais.  \n",
    "\n",
    "**bootstrap:** define se cada árvore é treinada com amostras com reposição (bootstrap). Quando True, cada árvore treina em um conjunto levemente diferente.  \n",
    "\n",
    "**max_samples:** só é usado quando bootstrap=True. Controla quantas amostras (linhas) entram em cada bootstrap (pode ser fração ou número). Reduzindo esse valor, você aumenta diversidade e pode reduzir custo, mas pode perder informação.  \n",
    "\n",
    "**criterion:** métrica usada para escolher a melhor divisão em cada nó. Em classificação, exemplos comuns são gini/entropy/log_loss; em regressão, squared_error/absolute_error (dependendo da implementação/versão).  \n",
    "\n",
    "**max_depth:** profundidade máxima das árvores. Limitar profundidade reduz overfitting e controla a complexidade do modelo.  \n",
    "\n",
    "**min_samples_split:** número mínimo de amostras para um nó poder ser dividido. Valores maiores tornam as árvores mais conservadoras (menos complexas).  \n",
    "\n",
    "**min_samples_leaf:** número mínimo de amostras em um nó folha. Ajuda a evitar folhas “muito específicas” e melhora generalização.  \n",
    "\n",
    "**max_leaf_nodes:** limita o número máximo de folhas por árvore. É outro controle direto de complexidade.  \n",
    "\n",
    "**min_impurity_decrease:** uma divisão só acontece se reduzir a impureza pelo menos esse valor. Funciona como um “freio” para splits com ganho pequeno.  \n",
    "\n",
    "**ccp_alpha:** parâmetro de poda por complexidade (cost-complexity pruning). Valores maiores tendem a simplificar as árvores (reduzindo complexidade).  \n",
    "\n",
    "**class_weight (classificação):** ajusta o peso das classes no treinamento, útil quando há desbalanceamento (uma classe muito mais frequente que outra).  \n",
    "\n",
    "**oob_score:** quando bootstrap=True, permite calcular uma validação out-of-bag usando as amostras que ficaram “fora” do bootstrap como validação interna (o resultado fica disponível em oob_score_ após o fit).  \n",
    "\n",
    "**random_state:** semente para reprodutibilidade (garante o mesmo resultado ao rodar novamente, quando aplicável).  \n",
    "\n",
    "**n_jobs:** paraleliza treino/predição usando mais núcleos da CPU (ex.: -1 usa todos).  \n",
    "\n",
    "**warm_start:** permite reaproveitar árvores já treinadas e adicionar mais depois (por exemplo, aumentar n_estimators sem recomeçar do zero).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PrevisaoVenda)",
   "language": "python",
   "name": "previsaovenda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
